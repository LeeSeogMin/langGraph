# app.py
# LangGraph+RAG ì—ì´ì „íŠ¸ë¥¼ ìœ„í•œ Streamlit ì›¹ ì¸í„°í˜ì´ìŠ¤

import os
import json
import logging
import pandas as pd
from dotenv import load_dotenv
import streamlit as st
from typing import Dict, List, Any, Optional
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime

# ë¬¸ì„œ ê´€ë¦¬ ëª¨ë“ˆ ì„í¬íŠ¸
from document_manager import DocumentManager

# LangGraph ì—ì´ì „íŠ¸ ëª¨ë“ˆ ì„í¬íŠ¸
from rag_agent import (
    build_rag_agent_graph,
    translate_to_korean,
    AgentState,
    HumanMessage
)

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# API í‚¤ ì„¤ì •
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY", "")
GOOGLE_CSE_ID_GENERAL = os.getenv("GOOGLE_CSE_ID_GENERAL", "")
GOOGLE_CSE_ID_SCHOLAR = os.getenv("GOOGLE_CSE_ID_SCHOLAR", "")

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="LangGraph+RAG ì—ì´ì „íŠ¸",
    page_icon="ğŸ§ ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if "document_manager" not in st.session_state:
    st.session_state.document_manager = None
    
if "agent_graph" not in st.session_state:
    st.session_state.agent_graph = None

if "api_keys_valid" not in st.session_state:
    st.session_state.api_keys_valid = False

def initialize_managers():
    """ë¬¸ì„œ ê´€ë¦¬ìì™€ ì—ì´ì „íŠ¸ ê·¸ë˜í”„ ì´ˆê¸°í™”"""
    if not st.session_state.api_keys_valid:
        st.warning("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì • íƒ­ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        return False
    
    try:
        # ë¬¸ì„œ ê´€ë¦¬ì ì´ˆê¸°í™”
        if st.session_state.document_manager is None:
            st.session_state.document_manager = DocumentManager(
                vector_db_path="./chroma_db",
                openai_api_key=OPENAI_API_KEY
            )
            logger.info("ë¬¸ì„œ ê´€ë¦¬ì ì´ˆê¸°í™” ì™„ë£Œ")
        
        # ì—ì´ì „íŠ¸ ê·¸ë˜í”„ ì´ˆê¸°í™”
        if st.session_state.agent_graph is None:
            st.session_state.agent_graph = build_rag_agent_graph()
            logger.info("ì—ì´ì „íŠ¸ ê·¸ë˜í”„ ì´ˆê¸°í™” ì™„ë£Œ")
        
        return True
    
    except Exception as e:
        logger.error(f"ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
        st.error(f"ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return False

def validate_api_keys():
    """API í‚¤ ìœ íš¨ì„± ê²€ì‚¬"""
    if not OPENAI_API_KEY:
        st.sidebar.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False
    
    if not GOOGLE_API_KEY or not GOOGLE_CSE_ID_GENERAL:
        st.sidebar.warning("Google ê²€ìƒ‰ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    return True if OPENAI_API_KEY else False

def send_message(query: str):
    """ì—ì´ì „íŠ¸ì— ë©”ì‹œì§€ ì „ì†¡ ë° ì‘ë‹µ ì²˜ë¦¬"""
    if not query.strip():
        return
    
    if not initialize_managers():
        return
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    user_message = {"role": "user", "content": query, "timestamp": datetime.now().strftime("%H:%M:%S")}
    st.session_state.chat_history.append(user_message)
    
    # ì²˜ë¦¬ ì¤‘ ë©”ì‹œì§€
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        message_placeholder.markdown("ğŸ§  ì²˜ë¦¬ ì¤‘...")
    
    try:
        # ì´ˆê¸° ìƒíƒœ ì„¤ì •
        initial_state = {
            "messages": [HumanMessage(content=query)],
            "intermediate_steps": [],
            "retrieved_documents": [],  # None ëŒ€ì‹  ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì´ˆê¸°í™”
            "query_analysis": {}  # None ëŒ€ì‹  ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¡œ ì´ˆê¸°í™”
        }
        
        # ì—ì´ì „íŠ¸ ê·¸ë˜í”„ ì‹¤í–‰
        last_ai_response = ""
        search_results = []
        retrieved_docs = []
        
        for event in st.session_state.agent_graph.stream(initial_state, {"recursion_limit": 10}):
            event_node = list(event.keys())[0]
            event_data = event[event_node]
            
            if event_node == "rag_retrieval" and "retrieved_documents" in event_data:
                retrieved_docs = event_data["retrieved_documents"] or []
                
                # ê²€ìƒ‰ëœ ë¬¸ì„œ ì •ë³´ í‘œì‹œ
                if retrieved_docs:
                    doc_info = []
                    for i, doc in enumerate(retrieved_docs):
                        source = doc.metadata.get("source", "ì•Œ ìˆ˜ ì—†ëŠ” ì¶œì²˜")
                        doc_info.append(f"ğŸ“„ ë¬¸ì„œ {i+1}: {source} (ê´€ë ¨ë„: {100 - i*10:.0f}%)")
                    
                    message_placeholder.markdown(
                        "ğŸ” ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤:\n" + "\n".join(doc_info) + "\n\nğŸ§  ë‹µë³€ ìƒì„± ì¤‘..."
                    )
            
            if "messages" in event_data:
                for msg in event_data["messages"]:
                    # ë„êµ¬ ë©”ì‹œì§€ ì²˜ë¦¬ (ê²€ìƒ‰ ê²°ê³¼)
                    if hasattr(msg, 'name') and msg.name in ["google_search", "google_scholar_search"]:
                        search_results.append({
                            "tool": msg.name,
                            "content": msg.content[:500] + "..." if len(msg.content) > 500 else msg.content
                        })
                        tool_name = "Google ê²€ìƒ‰" if msg.name == "google_search" else "Google Scholar ê²€ìƒ‰"
                        message_placeholder.markdown(
                            f"ğŸ” {tool_name} ê²°ê³¼ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘..."
                        )
                    
                    # AI ì‘ë‹µ ì²˜ë¦¬
                    elif hasattr(msg, 'content') and not hasattr(msg, 'name'):
                        korean_content = translate_to_korean(msg.content)
                        last_ai_response = korean_content
                        message_placeholder.markdown(korean_content)
        
        # ìµœì¢… AI ì‘ë‹µ ì¶”ê°€
        if last_ai_response:
            # ê²€ìƒ‰ëœ ë¬¸ì„œ ë° ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€
            metadata = {
                "retrieved_docs": [
                    {"source": doc.metadata.get("source", "ì•Œ ìˆ˜ ì—†ëŠ” ì¶œì²˜")} 
                    for doc in retrieved_docs
                ],
                "search_results": search_results
            }
            
            st.session_state.chat_history.append({
                "role": "assistant", 
                "content": last_ai_response, 
                "metadata": metadata,
                "timestamp": datetime.now().strftime("%H:%M:%S")
            })
        
    except Exception as e:
        logger.error(f"ì—ì´ì „íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        message_placeholder.markdown(f"ğŸ˜µ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        st.session_state.chat_history.append({
            "role": "assistant", 
            "content": f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}",
            "timestamp": datetime.now().strftime("%H:%M:%S")
        })

def display_chat_history():
    """ì±„íŒ… ê¸°ë¡ í‘œì‹œ"""
    for message in st.session_state.chat_history:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            
            # ë©”íƒ€ë°ì´í„° í‘œì‹œ (í™•ì¥ ê°€ëŠ¥)
            if message["role"] == "assistant" and "metadata" in message:
                metadata = message["metadata"]
                
                # ê²€ìƒ‰ëœ ë¬¸ì„œ í‘œì‹œ
                if metadata.get("retrieved_docs"):
                    with st.expander("ğŸ“š ì°¸ì¡°ëœ ë‚´ë¶€ ë¬¸ì„œ", expanded=False):
                        for i, doc in enumerate(metadata["retrieved_docs"]):
                            st.markdown(f"{i+1}. **ì¶œì²˜**: {doc['source']}")
                
                # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
                if metadata.get("search_results"):
                    with st.expander("ğŸ” ì›¹ ê²€ìƒ‰ ê²°ê³¼", expanded=False):
                        for result in metadata["search_results"]:
                            tool_name = "Google ê²€ìƒ‰" if result["tool"] == "google_search" else "Google Scholar ê²€ìƒ‰"
                            st.markdown(f"**{tool_name}**:")
                            st.text(result["content"])

def display_document_management():
    """ë¬¸ì„œ ê´€ë¦¬ ì¸í„°í˜ì´ìŠ¤"""
    if not initialize_managers():
        return
    
    document_manager = st.session_state.document_manager
    
    st.markdown("## ğŸ“š ë¬¸ì„œ ê´€ë¦¬")
    
    # íƒ­ ìƒì„±
    tab1, tab2, tab3 = st.tabs(["ğŸ“„ ë¬¸ì„œ ì¶”ê°€", "ğŸ“‹ ë¬¸ì„œ ëª©ë¡", "ğŸ“Š í†µê³„"])
    
    # ë¬¸ì„œ ì¶”ê°€ íƒ­
    with tab1:
        st.markdown("### ìƒˆ ë¬¸ì„œ ì¶”ê°€")
        
        upload_method = st.radio(
            "ì¶”ê°€ ë°©ì‹ ì„ íƒ:",
            ["íŒŒì¼ ì—…ë¡œë“œ", "ë””ë ‰í† ë¦¬ ê²½ë¡œ ì§€ì •"]
        )
        
        tags = st.text_input("íƒœê·¸ (ì‰¼í‘œë¡œ êµ¬ë¶„):", "").strip()
        tag_list = [tag.strip() for tag in tags.split(",")] if tags else []
        
        if upload_method == "íŒŒì¼ ì—…ë¡œë“œ":
            uploaded_files = st.file_uploader(
                "ë¬¸ì„œ íŒŒì¼ ì„ íƒ (txt, pdf, md, csv ë“±)",
                accept_multiple_files=True,
                type=["txt", "pdf", "md", "csv", "xlsx"]
            )
            
            if uploaded_files and st.button("ì„ íƒí•œ íŒŒì¼ ì¶”ê°€", type="primary"):
                for uploaded_file in uploaded_files:
                    # ì„ì‹œ íŒŒì¼ ì €ì¥
                    temp_file_path = os.path.join("./temp_uploads", uploaded_file.name)
                    os.makedirs(os.path.dirname(temp_file_path), exist_ok=True)
                    
                    with open(temp_file_path, "wb") as f:
                        f.write(uploaded_file.getbuffer())
                    
                    # ë¬¸ì„œ ì¶”ê°€
                    success = document_manager.add_document(temp_file_path, tag_list)
                    
                    # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                    if os.path.exists(temp_file_path):
                        os.remove(temp_file_path)
                    
                    if success:
                        st.success(f"'{uploaded_file.name}' ì¶”ê°€ ì™„ë£Œ")
                    else:
                        st.error(f"'{uploaded_file.name}' ì¶”ê°€ ì‹¤íŒ¨")
        
        else:  # ë””ë ‰í† ë¦¬ ê²½ë¡œ ì§€ì •
            directory_path = st.text_input("ë¬¸ì„œ ë””ë ‰í† ë¦¬ ê²½ë¡œ:", "./documents")
            
            if directory_path and st.button("ë””ë ‰í† ë¦¬ ë‚´ ë¬¸ì„œ ì¶”ê°€", type="primary"):
                if not os.path.exists(directory_path):
                    st.error(f"ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {directory_path}")
                else:
                    with st.spinner("ë¬¸ì„œ ì¶”ê°€ ì¤‘..."):
                        results = document_manager.add_directory(directory_path, tag_list)
                        st.success(
                            f"ë””ë ‰í† ë¦¬ ì²˜ë¦¬ ì™„ë£Œ: {results['success']}ê°œ ì„±ê³µ, "
                            f"{results['failed']}ê°œ ì‹¤íŒ¨, {results['skipped']}ê°œ ê±´ë„ˆëœ€"
                        )
    
    # ë¬¸ì„œ ëª©ë¡ íƒ­
    with tab2:
        st.markdown("### ì¸ë±ì‹±ëœ ë¬¸ì„œ ëª©ë¡")
        
        # ë¬¸ì„œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        docs_df = document_manager.list_documents()
        
        if docs_df.empty:
            st.info("ì¸ë±ì‹±ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. 'ë¬¸ì„œ ì¶”ê°€' íƒ­ì—ì„œ ë¬¸ì„œë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        else:
            st.dataframe(docs_df, use_container_width=True)
            
            # ë¬¸ì„œ ì‚­ì œ ê¸°ëŠ¥
            if not docs_df.empty:
                st.markdown("### ë¬¸ì„œ ì‚­ì œ")
                doc_to_remove = st.selectbox(
                    "ì‚­ì œí•  ë¬¸ì„œ ì„ íƒ:",
                    options=docs_df["filename"].tolist()
                )
                
                if st.button("ì„ íƒí•œ ë¬¸ì„œ ì‚­ì œ", type="secondary"):
                    if document_manager.remove_document(filename=doc_to_remove):
                        st.success(f"'{doc_to_remove}' ì‚­ì œ ì™„ë£Œ")
                    else:
                        st.error(f"'{doc_to_remove}' ì‚­ì œ ì‹¤íŒ¨")
    
    # í†µê³„ íƒ­
    with tab3:
        st.markdown("### ë¬¸ì„œ í†µê³„")
        
        stats = document_manager.get_statistics()
        
        col1, col2 = st.columns(2)
        
        with col1:
            # ê¸°ë³¸ í†µê³„
            st.metric("ì´ ë¬¸ì„œ ìˆ˜", stats["total_documents"])
            st.metric("ì´ ì²­í¬ ìˆ˜", stats["total_chunks"])
            st.markdown(f"**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: {stats['last_updated']}")
            
            # íƒœê·¸ í†µê³„
            if stats["tags"]:
                st.markdown("#### íƒœê·¸ë³„ ë¬¸ì„œ ìˆ˜")
                tags_df = pd.DataFrame(
                    {"íƒœê·¸": list(stats["tags"].keys()), "ë¬¸ì„œ ìˆ˜": list(stats["tags"].values())}
                ).sort_values("ë¬¸ì„œ ìˆ˜", ascending=False)
                
                st.dataframe(tags_df, use_container_width=True)
        
        with col2:
            # íŒŒì¼ ìœ í˜• í†µê³„
            if stats["file_types"]:
                st.markdown("#### íŒŒì¼ ìœ í˜•ë³„ ë¬¸ì„œ ìˆ˜")
                
                fig = px.pie(
                    names=list(stats["file_types"].keys()),
                    values=list(stats["file_types"].values()),
                    title="íŒŒì¼ ìœ í˜• ë¶„í¬"
                )
                st.plotly_chart(fig, use_container_width=True)
            
            # ì²­í¬ ëŒ€ë¹„ ë¬¸ì„œ ë¹„ìœ¨
            if stats["total_documents"] > 0:
                st.markdown("#### í‰ê·  ì²­í¬ ìˆ˜")
                avg_chunks = stats["total_chunks"] / stats["total_documents"]
                
                fig = go.Figure(go.Indicator(
                    mode="gauge+number",
                    value=avg_chunks,
                    title={"text": "ë¬¸ì„œë‹¹ í‰ê·  ì²­í¬ ìˆ˜"},
                    gauge={"axis": {"range": [0, max(10, avg_chunks * 1.5)]}}
                ))
                st.plotly_chart(fig, use_container_width=True)

def display_settings():
    """ì„¤ì • ì¸í„°í˜ì´ìŠ¤"""
    st.markdown("## âš™ï¸ ì„¤ì •")
    
    # API í‚¤ ì…ë ¥
    st.markdown("### API í‚¤ ì„¤ì •")
    
    openai_key = st.text_input(
        "OpenAI API í‚¤",
        value=OPENAI_API_KEY,
        type="password",
        help="OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”. í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¡œë“œëœ ê°’ì´ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ ì±„ì›Œì§‘ë‹ˆë‹¤."
    )
    
    google_key = st.text_input(
        "Google API í‚¤",
        value=GOOGLE_API_KEY,
        type="password",
        help="Google Custom Search API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”."
    )
    
    google_cse_id = st.text_input(
        "Google CSE ID (ì¼ë°˜)",
        value=GOOGLE_CSE_ID_GENERAL,
        help="Google Custom Search Engine IDë¥¼ ì…ë ¥í•˜ì„¸ìš”."
    )
    
    google_cse_id_scholar = st.text_input(
        "Google CSE ID (Scholar)",
        value=GOOGLE_CSE_ID_SCHOLAR,
        help="í•™ìˆ  ê²€ìƒ‰ìš© Google Custom Search Engine IDë¥¼ ì…ë ¥í•˜ì„¸ìš”."
    )
    
    # API í‚¤ ì €ì¥
    if st.button("API í‚¤ ì €ì¥", type="primary"):
        # .env íŒŒì¼ ì—…ë°ì´íŠ¸
        with open(".env", "w") as f:
            f.write(f"OPENAI_API_KEY={openai_key}\n")
            f.write(f"GOOGLE_API_KEY={google_key}\n")
            f.write(f"GOOGLE_CSE_ID_GENERAL={google_cse_id}\n")
            f.write(f"GOOGLE_CSE_ID_SCHOLAR={google_cse_id_scholar}\n")
        
        st.success("API í‚¤ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì¬ì‹œì‘í•˜ì„¸ìš”.")
    
    # ì„¤ì • ì •ë³´
    st.markdown("### ë²¡í„° DB ì„¤ì •")
    vector_db_path = "./chroma_db"
    
    if os.path.exists(vector_db_path):
        st.info(f"ë²¡í„° DB ê²½ë¡œ: {os.path.abspath(vector_db_path)}")
        db_size = sum(os.path.getsize(os.path.join(root, file)) for root, _, files in os.walk(vector_db_path) for file in files)
        st.metric("ë²¡í„° DB í¬ê¸°", f"{db_size / (1024 * 1024):.2f} MB")
    else:
        st.warning(f"ë²¡í„° DB ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {vector_db_path}")
    
    # ê³ ê¸‰ ì„¤ì •
    with st.expander("ê³ ê¸‰ ì„¤ì •", expanded=False):
        if st.button("ë²¡í„° DB ì´ˆê¸°í™” (ëª¨ë“  ë¬¸ì„œ ì‚­ì œ)", type="secondary"):
            if st.session_state.document_manager:
                confirm = st.text_input(
                    "ì •ë§ë¡œ ëª¨ë“  ë¬¸ì„œë¥¼ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? ì‚­ì œí•˜ë ¤ë©´ 'DELETE'ë¥¼ ì…ë ¥í•˜ì„¸ìš”:",
                    key="confirm_delete"
                )
                
                if confirm == "DELETE":
                    import shutil
                    try:
                        # ë²¡í„° DB ë””ë ‰í† ë¦¬ ì‚­ì œ ë° ì¬ìƒì„±
                        shutil.rmtree(vector_db_path, ignore_errors=True)
                        os.makedirs(vector_db_path, exist_ok=True)
                        
                        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
                        st.session_state.document_manager = None
                        st.session_state.agent_graph = None
                        
                        st.success("ë²¡í„° DBê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì„¸ìš”.")
                    except Exception as e:
                        st.error(f"ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        # ëª¨ë¸ ì„¤ì •
        st.markdown("### ëª¨ë¸ ì„¤ì •")
        
        model_option = st.selectbox(
            "ì‚¬ìš©í•  OpenAI ëª¨ë¸:",
            options=["gpt-3.5-turbo-16k", "gpt-4", "gpt-4-turbo"],
            index=0,
            help="ë” ê³ ê¸‰ ëª¨ë¸ì€ ì„±ëŠ¥ì´ ì¢‹ì§€ë§Œ ë¹„ìš©ì´ ë” ë†’ìŠµë‹ˆë‹¤."
        )
        
        chunk_size = st.slider(
            "ë¬¸ì„œ ì²­í¬ í¬ê¸°:",
            min_value=500,
            max_value=2000,
            value=1000,
            step=100,
            help="ë¬¸ì„œë¥¼ ë¶„í• í•  ë•Œ ê° ì²­í¬ì˜ í¬ê¸°(ê¸€ì ìˆ˜)ì…ë‹ˆë‹¤. ë„ˆë¬´ ì‘ìœ¼ë©´ ì»¨í…ìŠ¤íŠ¸ê°€ ë¶€ì¡±í•˜ê³ , ë„ˆë¬´ í¬ë©´ ê´€ë ¨ì„±ì´ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )
        
        retrieval_count = st.slider(
            "ê²€ìƒ‰ ê²°ê³¼ ìˆ˜:",
            min_value=1,
            max_value=10,
            value=4,
            step=1,
            help="ì§ˆë¬¸ì— ëŒ€í•´ ë²¡í„° DBì—ì„œ ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜ì…ë‹ˆë‹¤."
        )
        
        if st.button("ëª¨ë¸ ì„¤ì • ì €ì¥", type="primary"):
            # ì„¤ì • íŒŒì¼ë¡œ ì €ì¥
            config = {
                "model": model_option,
                "chunk_size": chunk_size,
                "retrieval_count": retrieval_count,
                "updated_at": datetime.now().isoformat()
            }
            
            with open("agent_config.json", "w", encoding="utf-8") as f:
                json.dump(config, f, ensure_ascii=False, indent=2)
            
            st.success("ëª¨ë¸ ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ì‹¤í–‰ë¶€í„° ì ìš©ë©ë‹ˆë‹¤.")

def display_doc_browser():
    """ë¬¸ì„œ ë¸Œë¼ìš°ì € ì¸í„°í˜ì´ìŠ¤"""
    if not initialize_managers():
        return
    
    document_manager = st.session_state.document_manager
    
    st.markdown("## ğŸ” ë¬¸ì„œ ë¸Œë¼ìš°ì €")
    
    # ë¬¸ì„œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    docs_df = document_manager.list_documents()
    
    if docs_df.empty:
        st.info("ì¸ë±ì‹±ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. 'ë¬¸ì„œ ê´€ë¦¬' íƒ­ì—ì„œ ë¬¸ì„œë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        return
    
    # ê²€ìƒ‰ ê¸°ëŠ¥
    st.markdown("### ë¬¸ì„œ ê²€ìƒ‰")
    
    search_query = st.text_input("ê²€ìƒ‰ì–´ ì…ë ¥:")
    search_count = st.slider("ê²€ìƒ‰ ê²°ê³¼ ìˆ˜:", min_value=1, max_value=10, value=3)
    
    # íƒœê·¸ í•„í„°
    all_tags = set()
    for _, metadata in document_manager.document_metadata["documents"].items():
        all_tags.update(metadata.get("tags", []))
    
    selected_tags = st.multiselect(
        "íƒœê·¸ í•„í„°:",
        options=sorted(list(all_tags)),
        help="íŠ¹ì • íƒœê·¸ê°€ ìˆëŠ” ë¬¸ì„œë§Œ ê²€ìƒ‰í•˜ë ¤ë©´ ì„ íƒí•˜ì„¸ìš”."
    )
    
    filter_criteria = {"tags": {"$in": selected_tags}} if selected_tags else None
    
    if search_query and st.button("ê²€ìƒ‰", type="primary"):
        with st.spinner("ê²€ìƒ‰ ì¤‘..."):
            results = document_manager.search_documents(
                search_query, k=search_count, filter_criteria=filter_criteria
            )
            
            if results:
                st.markdown(f"### ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ ë¬¸ì„œ ì°¾ìŒ")
                
                for i, doc in enumerate(results):
                    with st.expander(f"ë¬¸ì„œ {i+1}: {doc.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ëŠ” ì¶œì²˜')}", expanded=i==0):
                        st.markdown("#### ë¬¸ì„œ ì •ë³´")
                        st.json({
                            "source": doc.metadata.get("source", "ì•Œ ìˆ˜ ì—†ìŒ"),
                            "added_at": doc.metadata.get("added_at", "ì•Œ ìˆ˜ ì—†ìŒ"),
                            "tags": doc.metadata.get("tags", []),
                        })
                        
                        st.markdown("#### ë¬¸ì„œ ë‚´ìš©")
                        st.text_area(
                            "ë‚´ìš©",
                            value=doc.page_content,
                            height=300,
                            disabled=True
                        )
            else:
                st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # ë¬¸ì„œ ëª©ë¡ ë¸Œë¼ìš°ì§•
    st.markdown("### ë¬¸ì„œ ëª©ë¡ ë¸Œë¼ìš°ì§•")
    
    selected_document = st.selectbox(
        "ë¬¸ì„œ ì„ íƒ:",
        options=docs_df["filename"].tolist()
    )
    
    if selected_document:
        # ë¬¸ì„œ í•´ì‹œ ì°¾ê¸°
        selected_hash = None
        for file_hash, metadata in document_manager.document_metadata["documents"].items():
            if metadata["filename"] == selected_document:
                selected_hash = file_hash
                break
        
        if selected_hash:
            # í•´ë‹¹ ë¬¸ì„œì˜ ì²­í¬ ê²€ìƒ‰
            docs = document_manager.vector_store._collection.get(
                where={"file_hash": selected_hash}
            )
            
            if docs and docs["documents"]:
                st.markdown(f"### {selected_document} ì²­í¬")
                
                for i, (doc_id, content) in enumerate(zip(docs["ids"], docs["documents"])):
                    metadata = docs["metadatas"][i] if i < len(docs["metadatas"]) else {}
                    
                    with st.expander(f"ì²­í¬ {i+1} (ID: {doc_id[:8]}...)", expanded=i==0):
                        st.markdown("#### ë©”íƒ€ë°ì´í„°")
                        st.json(metadata)
                        
                        st.markdown("#### ë‚´ìš©")
                        st.text_area(
                            "ì²­í¬ ë‚´ìš©",
                            value=content,
                            height=200,
                            disabled=True
                        )
            else:
                st.warning(f"'{selected_document}'ì˜ ì²­í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

def display_chat_interface():
    """ì±„íŒ… ì¸í„°í˜ì´ìŠ¤"""
    st.markdown("## ğŸ¤– LangGraph+RAG ì—ì´ì „íŠ¸")
    
    # API í‚¤ í™•ì¸
    if not st.session_state.api_keys_valid:
        st.warning("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì • íƒ­ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        return
    
    # ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
    if not initialize_managers():
        return
    
    # ì±„íŒ… ê¸°ë¡ í‘œì‹œ
    display_chat_history()
    
    # ì‚¬ìš©ì ì…ë ¥
    user_query = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...")
    
    if user_query:
        send_message(user_query)
        st.rerun()  # ì±„íŒ… ê¸°ë¡ ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨

def display_about():
    """ì†Œê°œ í˜ì´ì§€"""
    st.markdown("## ğŸ“– LangGraph+RAG ì—ì´ì „íŠ¸ ì†Œê°œ")
    
    st.markdown("""
    ### í”„ë¡œì íŠ¸ ê°œìš”
    
    ì´ ì• í”Œë¦¬ì¼€ì´ì…˜ì€ LangGraphì™€ RAG(Retrieval-Augmented Generation)ë¥¼ ê²°í•©í•œ ê³ ê¸‰ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. 
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ë‚´ë¶€ ë¬¸ì„œ ì§€ì‹ë² ì´ìŠ¤ì™€ ì›¹ ê²€ìƒ‰ì„ ê²°í•©í•˜ì—¬ ì •í™•í•˜ê³  ê·¼ê±° ìˆëŠ” ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.
    
    ### ì£¼ìš” ê¸°ëŠ¥
    
    - **ë¬¸ì„œ ê´€ë¦¬**: ë‹¤ì–‘í•œ í˜•ì‹(TXT, PDF, CSV, MD ë“±)ì˜ ë¬¸ì„œë¥¼ ì§€ì‹ ë² ì´ìŠ¤ì— ì¶”ê°€í•˜ê³  ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - **RAG ì§ˆì˜ì‘ë‹µ**: ë‚´ë¶€ ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤.
    - **ì›¹ ê²€ìƒ‰ í†µí•©**: í•„ìš”í•œ ê²½ìš° Google ê²€ìƒ‰ APIë¥¼ í†µí•´ ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    - **ëŒ€í™” ê¸°ë¡**: ì§ˆë¬¸ê³¼ ë‹µë³€ ê¸°ë¡ì„ ìœ ì§€í•˜ê³ , ê²€ìƒ‰ ë° ì°¸ì¡° ë¬¸ì„œë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - **ë¬¸ì„œ ë¸Œë¼ìš°ì €**: ì§€ì‹ ë² ì´ìŠ¤ ë‚´ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³  íƒìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    
    ### ê¸°ìˆ  ìŠ¤íƒ
    
    - **LangGraph**: ì§ˆì˜ì‘ë‹µ ì›Œí¬í”Œë¡œìš°ë¥¼ ê·¸ë˜í”„ í˜•íƒœë¡œ êµ¬í˜„í•˜ì—¬ ë³µì¡í•œ í”„ë¡œì„¸ìŠ¤ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.
    - **LangChain**: ë¬¸ì„œ ì²˜ë¦¬, ë²¡í„° ì €ì¥ì†Œ, ì„ë² ë”© ë“± RAG ê¸°ëŠ¥ì„ êµ¬í˜„í•©ë‹ˆë‹¤.
    - **OpenAI API**: ëŒ€í™” ìƒì„±ê³¼ ë¬¸ì„œ ì„ë² ë”©ì— ì‚¬ìš©ë©ë‹ˆë‹¤.
    - **Google Search API**: ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
    - **Chroma DB**: ë¬¸ì„œì˜ ë²¡í„° ì„ë² ë”©ì„ ì €ì¥í•˜ê³  ê²€ìƒ‰í•©ë‹ˆë‹¤.
    - **Streamlit**: ì›¹ ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.
    
    ### ì‚¬ìš© ë°©ë²•
    
    1. **ì„¤ì • íƒ­**ì—ì„œ í•„ìš”í•œ API í‚¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
    2. **ë¬¸ì„œ ê´€ë¦¬** íƒ­ì—ì„œ ì§€ì‹ ë² ì´ìŠ¤ì— ë¬¸ì„œë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
    3. **ì±„íŒ…** íƒ­ì—ì„œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ê³  ë‹µë³€ì„ ë°›ìŠµë‹ˆë‹¤.
    4. **ë¬¸ì„œ ë¸Œë¼ìš°ì €** íƒ­ì—ì„œ ì§€ì‹ ë² ì´ìŠ¤ ë‚´ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³  íƒìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    
    ### ì°¸ê³  ìë£Œ
    
    - [LangChain ë¬¸ì„œ](https://python.langchain.com/docs/get_started/introduction)
    - [LangGraph ë¬¸ì„œ](https://python.langchain.com/docs/langgraph)
    - [RAG ì•„í‚¤í…ì²˜ ê°€ì´ë“œ](https://www.pinecone.io/learn/retrieval-augmented-generation/)
    - [Chroma DB ë¬¸ì„œ](https://docs.trychroma.com/)
    """)
    
    # ì‹œìŠ¤í…œ ì •ë³´
    st.markdown("### ì‹œìŠ¤í…œ ì •ë³´")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**í™˜ê²½ ì„¤ì •**")
        
        if os.path.exists("./chroma_db"):
            db_size = sum(os.path.getsize(os.path.join(root, file)) for root, _, files in os.walk("./chroma_db") for file in files)
            st.markdown(f"- ë²¡í„° DB í¬ê¸°: {db_size / (1024 * 1024):.2f} MB")
        else:
            st.markdown("- ë²¡í„° DB: ì´ˆê¸°í™” í•„ìš”")
        
        if os.path.exists("agent_config.json"):
            with open("agent_config.json", "r") as f:
                config = json.load(f)
            st.markdown(f"- ëª¨ë¸: {config.get('model', 'N/A')}")
            st.markdown(f"- ì²­í¬ í¬ê¸°: {config.get('chunk_size', 'N/A')}")
            st.markdown(f"- ìµœê·¼ ì„¤ì • ì—…ë°ì´íŠ¸: {config.get('updated_at', 'N/A')}")
        else:
            st.markdown("- ëª¨ë¸ ì„¤ì •: ê¸°ë³¸ê°’ ì‚¬ìš©")
    
    with col2:
        st.markdown("**API ìƒíƒœ**")
        
        if OPENAI_API_KEY:
            st.markdown("- OpenAI API: âœ… ì„¤ì •ë¨")
        else:
            st.markdown("- OpenAI API: âŒ ì„¤ì • í•„ìš”")
        
        if GOOGLE_API_KEY and GOOGLE_CSE_ID_GENERAL:
            st.markdown("- Google Search API: âœ… ì„¤ì •ë¨")
        else:
            st.markdown("- Google Search API: âŒ ì„¤ì • í•„ìš”")

def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    st.sidebar.title("LangGraph+RAG ì—ì´ì „íŠ¸")
    
    # API í‚¤ ìœ íš¨ì„± ê²€ì‚¬
    st.session_state.api_keys_valid = validate_api_keys()
    
    # ë©”ë‰´ ì„ íƒ
    menu = st.sidebar.radio(
        "ë©”ë‰´",
        ["ì±„íŒ…", "ë¬¸ì„œ ê´€ë¦¬", "ë¬¸ì„œ ë¸Œë¼ìš°ì €", "ì„¤ì •", "ì†Œê°œ"],
        index=0
    )
    
    # ì„ íƒëœ ë©”ë‰´ í‘œì‹œ
    if menu == "ì±„íŒ…":
        display_chat_interface()
    elif menu == "ë¬¸ì„œ ê´€ë¦¬":
        display_document_management()
    elif menu == "ë¬¸ì„œ ë¸Œë¼ìš°ì €":
        display_doc_browser()
    elif menu == "ì„¤ì •":
        display_settings()
    elif menu == "ì†Œê°œ":
        display_about()
    
    # í‘¸í„°
    st.sidebar.markdown("---")
    st.sidebar.caption("Â© 2025 LangGraph+RAG í”„ë¡œì íŠ¸")
    
    # ë””ë²„ê·¸ ì •ë³´
    if st.sidebar.checkbox("ë””ë²„ê·¸ ì •ë³´ í‘œì‹œ", value=False):
        st.sidebar.markdown("### ë””ë²„ê·¸ ì •ë³´")
        st.sidebar.write("ì„¸ì…˜ ìƒíƒœ:")
        debug_info = {
            "agent_graph": "ì´ˆê¸°í™”ë¨" if st.session_state.agent_graph else "ì´ˆê¸°í™” ì•ˆë¨",
            "document_manager": "ì´ˆê¸°í™”ë¨" if st.session_state.document_manager else "ì´ˆê¸°í™” ì•ˆë¨",
            "api_keys_valid": st.session_state.api_keys_valid,
            "chat_history_length": len(st.session_state.chat_history) if "chat_history" in st.session_state else 0
        }
        st.sidebar.json(debug_info)

if __name__ == "__main__":
    main()                                   